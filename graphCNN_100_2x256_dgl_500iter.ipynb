{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "graphCNN-100-2x256-dgl-500iter.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/justcherie/QD_Img_capt_plus_KG/blob/master/graphCNN_100_2x256_dgl_500iter.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KNsH1y6FZTdu",
        "colab_type": "code",
        "outputId": "c67bc786-2330-4535-94a0-bf9738ebba58",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)\n",
        "%cd /content/drive"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n",
            "/content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "STdgEec0ZgII",
        "colab_type": "code",
        "outputId": "eed71d06-5bc9-4e93-e690-ef32004052c3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        }
      },
      "source": [
        "!pwd\n",
        "%cd '/content/drive/My Drive/tensorflow-tutorial/quickdraw_tfrecord'\n",
        "!pwd\n",
        "!ls"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/tensorflow-tutorial/quickdraw_tfrecord\n",
            "/content/drive/My Drive/tensorflow-tutorial/quickdraw_tfrecord\n",
            "/content/drive/My Drive/tensorflow-tutorial/quickdraw_tfrecord\n",
            "archive\t\t\t\t    dgl_nx_25_combined_15cats_train.bin\n",
            "archive-codebug\t\t\t    dgl_nx_400_3cats_combined_test.bin\n",
            "dgl_combined_100_test.bin\t    dgl_nx_400_3cats_combined_train.bin\n",
            "dgl_combined_100_train.bin\t    dgl_nx_400_combined_15cats_test.bin\n",
            "dgl_nx_25_combined_15cats_test.bin  dgl_nx_400_combined_15cats_train.bin\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a8Yt-AKvZk0n",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "  label_dict = { 'alarm': 1 , 'clock': 2 , 'ambulance': 3 , 'angel': 4 , 'ant': 5 , 'barn': 6 , 'basket': 7 , \n",
        "'bee': 8 , 'bicycle': 9 , 'book':  10, 'bridge': 11 , 'bulldozer': 12 , 'bus': 13 , 'butterfly': 14 ,\n",
        " 'cactus': 15 , 'castle': 16 , 'cat': 17 , 'chair': 18 , 'couch': 19 , 'crab':  20, 'cruise': 21,\n",
        " 'ship': 22 , 'dolphin': 23 , 'duck': 24 , 'elephant': 25 , 'eye': 26 , 'face': 27 , 'fan': 28 , 'fire hydrant': 29 ,\n",
        " 'firetruck': 30 , 'flamingo': 31 , 'flower':  32, 'garden':  33, 'hand': 34 , 'hedgehog':  35, 'helicopter': 36 , 'kangaroo': 37 , 'key': 38 ,\n",
        " 'lighthouse': 39 , 'lion': 40 , 'map': 41 , 'mermaid': 42 , 'octopus': 43 , 'owl':  44, 'paintbrush':  45, 'palm tree': 46 , 'parrot': 47,\n",
        " 'passport': 48 , 'peas':  49, 'penguin': 50 , 'pig':  51, 'pineapple': 52 , 'postcard': 53 , 'power outlet': 54 , 'rabbit':  55, 'radio': 56 ,\n",
        " 'rain': 57 , 'rhinoceros':  58, 'roller coaster': 59 , 'sandwich': 60 , 'scorpion': 61, 'sea turtle':  62, 'sheep':  63, 'skull':  64, 'snail':  65,\n",
        " 'snowflake':  66, 'speedboat': 67 , 'spider':  68, 'strawberry': 69 , 'swan': 70 , 'swing set': 71 , 'tennis racquet':  72, 'the mona lisa': 73 ,\n",
        " 'toothbrush': 74 , 'truck': 75 , 'whale':  76, 'windmill': 77, 'airplane': 78, 'mosquito':79, 'yoga':80 }"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0DLzGfczZtNW",
        "colab_type": "code",
        "outputId": "da90d2f3-919c-447d-f9f8-fbc84bb43ab1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 190
        }
      },
      "source": [
        "# reference: https://docs.dgl.ai/tutorials/basics/4_batch.html\n",
        "\n",
        "!pip install dgl\n",
        "\"\"\"\n",
        ".. currentmodule:: dgl\n",
        "\n",
        "Batched Graph Classification with DGL\n",
        "=====================================\n",
        "\n",
        "**Author**: `Mufei Li <https://github.com/mufeili>`_,\n",
        "`Minjie Wang <https://jermainewang.github.io/>`_,\n",
        "`Zheng Zhang <https://shanghai.nyu.edu/academics/faculty/directory/zheng-zhang>`_.\n",
        "\n",
        "Graph classification is an important problem\n",
        "with applications across many fields -- bioinformatics, chemoinformatics, social\n",
        "network analysis, urban computing and cyber-security. Applying graph neural\n",
        "networks to this problem has been a popular approach recently (\n",
        "`Ying et al., 2018 <https://arxiv.org/abs/1806.08804>`_,\n",
        "`Cangea et al., 2018 <https://arxiv.org/abs/1811.01287>`_,\n",
        "`Knyazev et al., 2018 <https://arxiv.org/abs/1811.09595>`_,\n",
        "`Bianchi et al., 2019 <https://arxiv.org/abs/1901.01343>`_,\n",
        "`Liao et al., 2019 <https://arxiv.org/abs/1901.01484>`_,\n",
        "`Gao et al., 2019 <https://openreview.net/forum?id=HJePRoAct7>`_).\n",
        "\n",
        "This tutorial demonstrates:\n",
        " * batching multiple graphs of variable size and shape with DGL\n",
        " * training a graph neural network for a simple graph classification task\n",
        "\"\"\"\n",
        "\n",
        "###############################################################################\n",
        "# Simple Graph Classification Task\n",
        "# --------------------------------\n",
        "# In this tutorial, we will learn how to perform batched graph classification\n",
        "# with dgl via a toy example of classifying 8 types of regular graphs as below:\n",
        "#\n",
        "# .. image:: https://s3.us-east-2.amazonaws.com/dgl.ai/tutorial/batch/dataset_overview.png\n",
        "#     :align: center\n",
        "#\n",
        "# We implement a synthetic dataset :class:`data.MiniGCDataset` in DGL. The dataset has 8\n",
        "# different types of graphs and each class has the same number of graph samples.\n",
        "\n",
        "from dgl.data import MiniGCDataset\n",
        "import matplotlib.pyplot as plt\n",
        "import networkx as nx\n",
        "import os\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting dgl\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e4/ba/d15ce7fb56958f21d4e9815f96344d92c4982f3fb933a0e987e78cb787e5/dgl-0.4.1-cp36-cp36m-manylinux1_x86_64.whl (2.4MB)\n",
            "\u001b[K     |████████████████████████████████| 2.4MB 6.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.6/dist-packages (from dgl) (1.17.4)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from dgl) (1.3.2)\n",
            "Requirement already satisfied: networkx>=2.1 in /usr/local/lib/python3.6/dist-packages (from dgl) (2.4)\n",
            "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.6/dist-packages (from networkx>=2.1->dgl) (4.4.1)\n",
            "Installing collected packages: dgl\n",
            "Successfully installed dgl-0.4.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z20A7FVLZ0Mf",
        "colab_type": "code",
        "outputId": "c366b897-8888-422d-94c9-c9409def7fcf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 264
        }
      },
      "source": [
        "from dgl.data.utils import load_graphs\n",
        "output_path = \"/content/drive/My Drive/tensorflow-tutorial/quickdraw_tfrecord/\"\n",
        "file_name = \"dgl_combined_100_train.bin\"\n",
        "glist, glabel_dict = load_graphs(os.path.join(output_path, file_name))\n",
        "\n",
        "i=2\n",
        "temp=tuple((glist[i],glabel_dict['label'].tolist()[i]))\n",
        "#graph, label = dataset[0]\n",
        "graph, label = temp\n",
        "fig, ax = plt.subplots()\n",
        "nx.draw(graph.to_networkx(), ax=ax)\n",
        "ax.set_title('Class: {:d}'.format(label))\n",
        "plt.show()\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAV0AAAD3CAYAAAC+eIeLAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nERJdgiAIHSHRJQiC0BESXYIgCB35/5cpJLIfXUozAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ADNRES0kZ6sY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "###############################################################################\n",
        "# Form a graph mini-batch\n",
        "# -----------------------\n",
        "# To train neural networks more efficiently, a common practice is to **batch**\n",
        "# multiple samples together to form a mini-batch. Batching fixed-shaped tensor\n",
        "# inputs is quite easy (for example, batching two images of size :math:`28\\times 28`\n",
        "# gives a tensor of shape :math:`2\\times 28\\times 28`). By contrast, batching graph inputs\n",
        "# has two challenges:\n",
        "#\n",
        "# * Graphs are sparse.\n",
        "# * Graphs can have various length (e.g. number of nodes and edges).\n",
        "#\n",
        "# To address this, DGL provides a :func:`dgl.batch` API. It leverages the trick that\n",
        "# a batch of graphs can be viewed as a large graph that have many disjoint\n",
        "# connected components. Below is a visualization that gives the general idea:\n",
        "#\n",
        "# .. image:: https://s3.us-east-2.amazonaws.com/dgl.ai/tutorial/batch/batch.png\n",
        "#     :width: 400pt\n",
        "#     :align: center\n",
        "#\n",
        "# We define the following ``collate`` function to form a mini-batch from a given\n",
        "# list of graph and label pairs.\n",
        "\n",
        "import dgl\n",
        "\n",
        "def collate(samples):\n",
        "    # The input `samples` is a list of pairs\n",
        "    #  (graph, label).\n",
        "    graphs, labels = map(list, zip(*samples))\n",
        "    batched_graph = dgl.batch(graphs)\n",
        "    return batched_graph, torch.tensor(labels)\n",
        "\n",
        "###############################################################################\n",
        "# The return type of :func:`dgl.batch` is still a graph (similar to the fact that\n",
        "# a batch of tensors is still a tensor). This means that any code that works\n",
        "# for one graph immediately works for a batch of graphs. More importantly,\n",
        "# since DGL processes messages on all nodes and edges in parallel, this greatly\n",
        "# improves efficiency.\n",
        "#\n",
        "# Graph Classifier\n",
        "# ----------------\n",
        "# The graph classification can be proceeded as follows:\n",
        "#\n",
        "# .. image:: https://s3.us-east-2.amazonaws.com/dgl.ai/tutorial/batch/graph_classifier.png\n",
        "#\n",
        "# From a batch of graphs, we first perform message passing/graph convolution\n",
        "# for nodes to \"communicate\" with others. After message passing, we compute a\n",
        "# tensor for graph representation from node (and edge) attributes. This step may\n",
        "# be called \"readout/aggregation\" interchangeably. Finally, the graph\n",
        "# representations can be fed into a classifier :math:`g` to predict the graph labels.\n",
        "#"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "khxu6TFzaCMA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Graph Convolution\n",
        "# -----------------\n",
        "# Our graph convolution operation is basically the same as that for GCN (checkout our \n",
        "# `tutorial <https://docs.dgl.ai/tutorials/models/1_gnn/1_gcn.html>`_). The only difference is\n",
        "# that we replace :math:`h_{v}^{(l+1)} = \\text{ReLU}\\left(b^{(l)}+\\sum_{u\\in\\mathcal{N}(v)}h_{u}^{(l)}W^{(l)}\\right)` by\n",
        "# :math:`h_{v}^{(l+1)} = \\text{ReLU}\\left(b^{(l)}+\\frac{1}{|\\mathcal{N}(v)|}\\sum_{u\\in\\mathcal{N}(v)}h_{u}^{(l)}W^{(l)}\\right)`.\n",
        "# The replacement of summation by average is to balance nodes with different\n",
        "# degrees, which gives a better performance for this experiment.\n",
        "#\n",
        "# Note that the self edges added in the dataset initialization allows us to\n",
        "# include the original node feature :math:`h_{v}^{(l)}` when taking the average.\n",
        "\n",
        "import dgl.function as fn\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "\n",
        "# Sends a message of node feature h.\n",
        "msg = fn.copy_src(src='h', out='m')\n",
        "\n",
        "def reduce(nodes):\n",
        "    \"\"\"Take an average over all neighbor node features hu and use it to\n",
        "    overwrite the original node feature.\"\"\"\n",
        "    accum = torch.mean(nodes.mailbox['m'], 1)\n",
        "    return {'h': accum}\n",
        "\n",
        "class NodeApplyModule(nn.Module):\n",
        "    \"\"\"Update the node feature hv with ReLU(Whv+b).\"\"\"\n",
        "    def __init__(self, in_feats, out_feats, activation):\n",
        "        super(NodeApplyModule, self).__init__()\n",
        "        self.linear = nn.Linear(in_feats, out_feats)\n",
        "        self.activation = activation\n",
        "\n",
        "    def forward(self, node):\n",
        "        h = self.linear(node.data['h'])\n",
        "        h = self.activation(h)\n",
        "        return {'h' : h}\n",
        "\n",
        "class GCN(nn.Module):\n",
        "    def __init__(self, in_feats, out_feats, activation):\n",
        "        super(GCN, self).__init__()\n",
        "        self.apply_mod = NodeApplyModule(in_feats, out_feats, activation)\n",
        "\n",
        "    def forward(self, g, feature):\n",
        "        # Initialize the node features with h.\n",
        "        g.ndata['h'] = feature\n",
        "        g.update_all(msg, reduce)\n",
        "        g.apply_nodes(func=self.apply_mod)\n",
        "        return g.ndata.pop('h')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1JVvyZokaKJT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "###############################################################################\n",
        "# Readout and Classification\n",
        "# --------------------------\n",
        "# For this demonstration, we consider initial node features to be their degrees.\n",
        "# After two rounds of graph convolution, we perform a graph readout by averaging\n",
        "# over all node features for each graph in the batch\n",
        "#\n",
        "# .. math::\n",
        "#\n",
        "#    h_g=\\frac{1}{|\\mathcal{V}|}\\sum_{v\\in\\mathcal{V}}h_{v}\n",
        "#\n",
        "# In DGL, :func:`dgl.mean_nodes` handles this task for a batch of\n",
        "# graphs with variable size. We then feed our graph representations into a\n",
        "# classifier with one linear layer to obtain pre-softmax logits.\n",
        "\n",
        "import torch.nn.functional as F\n",
        "\n",
        "\n",
        "class Classifier(nn.Module):\n",
        "    def __init__(self, in_dim, hidden_dim, n_classes):\n",
        "        super(Classifier, self).__init__()\n",
        "\n",
        "        self.layers = nn.ModuleList([\n",
        "            GCN(in_dim, hidden_dim, F.relu),\n",
        "            GCN(hidden_dim, hidden_dim, F.relu)])\n",
        "        self.classify = nn.Linear(hidden_dim, n_classes)\n",
        "\n",
        "    def forward(self, g):\n",
        "        # For undirected graphs, in_degree is the same as\n",
        "        # out_degree.\n",
        "        h = g.in_degrees().view(-1, 1).float()\n",
        "        for conv in self.layers:\n",
        "            h = conv(g, h)\n",
        "        g.ndata['h'] = h\n",
        "        hg = dgl.mean_nodes(g, 'h')\n",
        "        return self.classify(hg)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BfIEAj_KaOpr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "###############################################################################\n",
        "# Setup and Training\n",
        "# ------------------\n",
        "# We create a synthetic dataset of :math:`400` graphs with :math:`10` ~\n",
        "# :math:`20` nodes. :math:`320` graphs constitute a training set and\n",
        "# :math:`80` graphs constitute a test set.\n",
        "\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "# Create training and test sets.\n",
        "#trainset = MiniGCDataset(320, 10, 20)\n",
        "#testset = MiniGCDataset(80, 10, 20)\n",
        "\n",
        "from dgl.data.utils import load_graphs\n",
        "output_path = \"/content/drive/My Drive/tensorflow-tutorial/quickdraw_tfrecord\"\n",
        "file_name_train = \"dgl_combined_100_train.bin\"\n",
        "glist_train, label_dict_train = load_graphs(os.path.join(output_path, file_name_train))\n",
        "#i=2\n",
        "#temp=tuple((glist[i],label_dict['label'].tolist()[i]))\n",
        "\n",
        "import numpy as np\n",
        "#trainset = tuple((glist_train,label_dict_train['label'].tolist()))\n",
        "#trainset = np.array(([glist_train, label_dict_train['label'].tolist()])\n",
        "trainset = list( zip( glist_train, label_dict_train['label'].tolist() ))\n",
        "\n",
        "file_name_test = \"dgl_combined_100_test.bin\"\n",
        "glist_test, label_dict_test = load_graphs(os.path.join(output_path, file_name_test))\n",
        "testset = list( zip( glist_test, label_dict_test['label'].tolist() ))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TfoAw43LaWjj",
        "colab_type": "code",
        "outputId": "8ae5c577-6f36-474d-c2fc-fde301d0e695",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 231
        }
      },
      "source": [
        "\n",
        "# Use PyTorch's DataLoader and the collate function\n",
        "# defined before.\n",
        "data_loader = DataLoader(trainset, batch_size=32, shuffle=True,\n",
        "                         collate_fn=collate)\n",
        "\n",
        "# Create model\n",
        "#trainset_num_classes = len(np.unique(trainset[1]))\n",
        "#from operator import itemgetter \n",
        "#trainset_num_classes = len(np.unique(list(map(itemgetter(1), trainset))))\n",
        "trainset_num_classes = (len(label_dict.values())+1)\n",
        "#model = Classifier(1, 256, trainset.num_classes)\n",
        "model = Classifier(1, 256, trainset_num_classes)\n",
        "\n",
        "loss_func = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "model.train()\n",
        "\n",
        "epoch_losses = []\n",
        "num_epoches = 500\n",
        "weights = []\n",
        "labels_batch_run = []\n",
        "for epoch in range(num_epoches):\n",
        "    epoch_loss = 0\n",
        "    for iter, (bg, label) in enumerate(data_loader):\n",
        "        prediction = model(bg)\n",
        "        loss = loss_func(prediction, label)\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        epoch_loss += loss.detach().item()\n",
        "       \n",
        "    epoch_loss /= (iter + 1)\n",
        "    print('Epoch {}, loss {:.4f}'.format(epoch, epoch_loss))\n",
        "    epoch_losses.append(epoch_loss)\n",
        "\n",
        "###############################################################################\n",
        "# The learning curve of a run is presented below:\n",
        "\n",
        "plt.title('cross entropy averaged over minibatches')\n",
        "plt.plot(epoch_losses)\n",
        "plt.show()\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-e1591f6ea49a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m data_loader = DataLoader(trainset, batch_size=32, shuffle=True,\n\u001b[0m\u001b[1;32m      2\u001b[0m                          collate_fn=collate)\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Create model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m#trainset_num_classes = len(np.unique(trainset[1]))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'DataLoader' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ul-h3dKkafqg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "###############################################################################\n",
        "# The trained model is evaluated on the test set created. Note that for deployment\n",
        "# of the tutorial, we restrict our running time and you are likely to get a higher\n",
        "# accuracy (:math:`80` % ~ :math:`90` %) than the ones printed below.\n",
        "\n",
        "model.eval()\n",
        "# Convert a list of tuples to two lists\n",
        "test_X, test_Y = map(list, zip(*testset))\n",
        "label_Y = test_Y\n",
        "test_bg = dgl.batch(test_X)\n",
        "\n",
        "test_Y = torch.tensor(test_Y).float().view(-1, 1)\n",
        "probs_Y = torch.softmax(model(test_bg), 1)\n",
        "sampled_Y = torch.multinomial(probs_Y, 1)\n",
        "argmax_Y = torch.max(probs_Y, 1)[1].view(-1, 1)\n",
        "print('Accuracy of sampled predictions on the test set: {:.4f}%'.format(\n",
        "    (test_Y == sampled_Y.float()).sum().item() / len(test_Y) * 100))\n",
        "print('Accuracy of argmax predictions on the test set: {:4f}%'.format(\n",
        "    (test_Y == argmax_Y.float()).sum().item() / len(test_Y) * 100))\n",
        "\n",
        "\n",
        "   "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1fE7gZJpakgt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "def plot_tsne(title,labels,word_tsne):\n",
        "    import matplotlib.pyplot as plt\n",
        "    \n",
        "   \n",
        "    plt.figure( figsize=[10,10])\n",
        "    for i in range(len(word_tsne)):\n",
        "        x = word_tsne[i,0]\n",
        "        y = word_tsne[i,1]\n",
        "#        plt.scatter(x, y, marker='x', color='red')\n",
        "        plt.scatter(x, y, marker='o')\n",
        "#        plt.text(x+0.3, y+0.3, labels[i], fontsize=9)\n",
        "        plt.title(title)\n",
        "    plt.show()\n",
        "    \n",
        "    return\n",
        "\n",
        "from sklearn.manifold import TSNE\n",
        "#layer_tsne = TSNE(n_components=2).fit_transform(model(test_bg).tolist())\n",
        "#layer_tsne = TSNE(n_components=2).fit_transform(model(test_bg).tolist())\n",
        "\n",
        "#plot_tsne(\"Y prior softmax\",label_Y, layer_tsne)\n",
        "\n",
        "eval_list = []\n",
        "for graph in test_X:\n",
        "    eval_list.append(model.forward(graph).tolist())\n",
        "    \n",
        "layer_tsne = TSNE(n_components=2).fit_transform(eval_list)\n",
        "#plot_tsne(\"Y prior softmax\",label_Y, layer_tsne)\n",
        "\n",
        "label_Y_text = []\n",
        "for i in label_Y:\n",
        "    #label_Y_text.append(label_dict[label_Y[i]])\n",
        "    \n",
        "    label_Y_text.append( list(label_dict.keys())[list(label_dict.values()).index(label_Y[i])] )\n",
        "\n",
        "import seaborn as sns\n",
        "#iris = sns.load_dataset('iris')\n",
        "sns.scatterplot(x=layer_tsne[:,0], y=layer_tsne[:,1],\n",
        "              hue=label_Y_text)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}